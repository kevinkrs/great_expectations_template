{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14c2bbd",
   "metadata": {},
   "source": [
    "# Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea03b0",
   "metadata": {},
   "source": [
    "The folowing notebook is a completely manual setup of a _great_expectations_ pipeline. Usually many of the steps (especially setup) are fulfilled by the _great_expectations_ clientl. This notebook is only for educational reasons to get a deeper understanding on what is going on within the library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f83264",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc195261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "from ruamel import yaml\n",
    "from great_expectations.core.batch import BatchRequest, RuntimeBatchRequest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8963d5",
   "metadata": {},
   "source": [
    "## Create datasource config and load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb97ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataContext to memory\n",
    "context = ge.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecb4b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_yaml=\"\"\"\n",
    "name: transactions_use_case\n",
    "class_name: Datasource\n",
    "execution_engine:\n",
    "  class_name: PandasExecutionEngine\n",
    "data_connectors:\n",
    "  default_inferred_data_connector_name:\n",
    "    class_name: InferredAssetFilesystemDataConnector\n",
    "    base_directory: ../data\n",
    "    default_regex:\n",
    "      group_names: \n",
    "        - data_asset_name\n",
    "      pattern: (.*)\n",
    "  default_runtime_data_connector_name:\n",
    "    class_name: RuntimeDataConnector\n",
    "    batch_identifiers:\n",
    "      - default_identifier_name\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c76bdfea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: PandasExecutionEngine\n",
      "Data Connectors:\n",
      "\tdefault_inferred_data_connector_name : InferredAssetFilesystemDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (3 of 3):\n",
      "\t\tarticles.csv (1 of 1): ['articles.csv']\n",
      "\t\ttransactions.csv (1 of 1): ['transactions.csv']\n",
      "\t\ttransactions_faulty.csv (1 of 1): ['transactions_faulty.csv']\n",
      "\n",
      "\tUnmatched data_references (0 of 0):[]\n",
      "\n",
      "\tdefault_runtime_data_connector_name:RuntimeDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (0 of 0):\n",
      "\t\tNote : RuntimeDataConnector will not have data_asset_names until they are passed in through RuntimeBatchRequest\n",
      "\n",
      "\tUnmatched data_references (0 of 0): []\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7f6086ff5b50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.test_yaml_config(data_source_yaml) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f2e55",
   "metadata": {},
   "source": [
    "After succesfully setting up the config and testing it, we have to load it to the appropriate palace in oure _great_expectations.yaml_ file wich has been created with the initialisation of great_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0c6ed37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1180/2045274942.py:1: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  context.add_datasource(**yaml.load(datasource_yaml))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7f6086f4e430>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.add_datasource(**yaml.load(datasource_yaml))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4bf00",
   "metadata": {},
   "source": [
    "## Testing the new datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb12dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=\"transactions_use_case\", # this has to be equal as the defined data_source_name in the datasource_yaml\n",
    "    data_connector_name=\"default_runtime_data_connector_name\",\n",
    "    data_asset_name=\"transactions\",  # This can be anything that identifies this data_asset for you\n",
    "    runtime_parameters={\"path\": \"./data/transactions.csv\"},  # Add your path here.\n",
    "    batch_identifiers={\"default_identifier_name\": \"default_identifier\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d76759b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"data_asset_type\": null,\n",
       "  \"expectation_suite_name\": \"test_suite\",\n",
       "  \"ge_cloud_id\": null,\n",
       "  \"expectations\": [],\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.14.6\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.create_expectation_suite(\n",
    "    expectation_suite_name=\"test_suite\", overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b7d9127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date article_id  value\n",
      "0  05.07.2021      200XL  49.99\n",
      "1  20.06.2021       400S  19.99\n",
      "2  15.04.2021      200XL  49.99\n",
      "3  02.04.2021       500M  79.99\n",
      "4  02.04.2021       100L  29.99\n"
     ]
    }
   ],
   "source": [
    "validator = context.get_validator(\n",
    "    batch_request=batch_request, expectation_suite_name=\"test_suite\"\n",
    ")\n",
    "print(validator.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f4a8e",
   "metadata": {},
   "source": [
    "# Creating an expectation suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc6b29",
   "metadata": {},
   "source": [
    "To create a testing pipeline with set of expectations a suite has to be created. It is a JSON with all expectations that will be run on a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096eaf7",
   "metadata": {},
   "source": [
    "There are 2 options to setup expectations.\n",
    "* Use the profiler and a \"healthy\" dataset to auto generate expectations based on the input tables form and simple metrics (mean, min, max) \n",
    "* Create an expectations JSON manually by utilizing already implemented expectations and/or create custom expectations to test against certain input data\n",
    "   \n",
    "This notebook will go with the latter approach. To use the profiler just run _great_expectations suite new_ and select the profiler option. This will start a new helper notebook where expectatins based on the input data are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe38da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from great_expectations.data_context.types.resource_identifiers import ExpectationSuiteIdentifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5009238b",
   "metadata": {},
   "source": [
    "### 1 Create expectation suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dca46b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"data_asset_type\": null,\n",
       "  \"expectation_suite_name\": \"transaction_validation_suite\",\n",
       "  \"ge_cloud_id\": null,\n",
       "  \"expectations\": [],\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.14.6\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.create_expectation_suite(\n",
    "    expectation_suite_name=\"transaction_validation_suite\", overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab3da8",
   "metadata": {},
   "source": [
    "### 2 Set suite to the new expectation suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8602d36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ExpectationSuite \"transaction_validation_suite\" containing 0 expectations.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    suite = context.get_expectation_suite(expectation_suite_name=expectation_suite_name)\n",
    "    print(\n",
    "        f'Loaded ExpectationSuite \"{suite.expectation_suite_name}\" containing {len(suite.expectations)} expectations.'\n",
    "    )\n",
    "except DataContextError:\n",
    "    suite = context.create_expectation_suite(\n",
    "        expectation_suite_name=expectation_suite_name\n",
    "    )\n",
    "    print(f'Created ExpectationSuite \"{suite.expectation_suite_name}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7800b78c",
   "metadata": {},
   "source": [
    "### 3 Create expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "948fe841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  article_id article_name  article_color_id article_size_id\n",
      "0       100L      T-Shirt               100               L\n",
      "1      200XL        Pants               200              XL\n",
      "2       300M        Jeans               300              XM\n",
      "3       400S          Hat               400               S\n",
      "4       500M     Sneakers               500               M\n",
      "['100L', '200XL', '300M', '400S', '500M']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_values_to_be_in_set\", \"kwargs\": {\"column\": \"article_id\", \"value_set\": [\"100L\", \"200XL\", \"300M\", \"400S\", \"500M\"]}, \"meta\": {\"notes\": {\"content\": \"The input value set is derived from the articles.csv. This way the validation data will always be compared \\n         to the currently available articles. Optionally another suite for checking articles may be beneficial\"}}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an Expectation\n",
    "articles = pd.read_csv((\"./data/articles.csv\"))\n",
    "print(articles.head())\n",
    "\n",
    "article_id= articles['article_id'].values.tolist()\n",
    "print(article_id)\n",
    "expectation_configuration = ExpectationConfiguration(\n",
    "   expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "   kwargs={\n",
    "      \"column\":\"article_id\",\n",
    "      \"value_set\": article_id\n",
    "   },\n",
    "   meta={\n",
    "       \"notes\": {\n",
    "         \"content\": \"\"\"The input value set is derived from the articles.csv. This way the validation data will always be compared \n",
    "         to the currently available articles. Optionally another suite for checking articles may be beneficial\"\"\"\n",
    "      }\n",
    "   }\n",
    ")\n",
    "# Add the Expectation to the suite\n",
    "suite.add_expectation(expectation_configuration=expectation_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a9088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4809885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30ce72e7",
   "metadata": {},
   "source": [
    "### 4 Save created expectations to expectation suite JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbdae1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_asset_type\": null,\n",
      "  \"expectation_suite_name\": \"transaction_validation_suite\",\n",
      "  \"ge_cloud_id\": null,\n",
      "  \"expectations\": [],\n",
      "  \"meta\": {\n",
      "    \"great_expectations_version\": \"0.14.6\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(context.get_expectation_suite(expectation_suite_name=expectation_suite_name))\n",
    "context.save_expectation_suite(expectation_suite=suite, expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "suite_identifier = ExpectationSuiteIdentifier(expectation_suite_name=expectation_suite_name)\n",
    "context.build_data_docs(resource_identifiers=[suite_identifier])\n",
    "context.open_data_docs(resource_identifier=suite_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99046ca0",
   "metadata": {},
   "source": [
    "# Calling single great_expectation functions with python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abffc6d",
   "metadata": {},
   "source": [
    "### Import the required data for check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a5da12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  article_id article_name  article_color_id article_size_id\n",
      "0       100L      T-Shirt               100               L\n",
      "1      200XL        Pants               200              XL\n",
      "2       300M        Jeans               300              XM\n",
      "3       400S          Hat               400               S\n",
      "4       500M     Sneakers               500               M\n",
      "['100L', '200XL', '300M', '400S', '500M']\n"
     ]
    }
   ],
   "source": [
    "transactions_df = ge.read_csv(\"./data/transactions.csv\")\n",
    "transactions_faulty_df = ge.read_csv(\"./data/transactions_faulty.csv\")\n",
    "\n",
    "# create set of all article id's\n",
    "articles = pd.read_csv((\"./data/articles.csv\"))\n",
    "print(articles.head())\n",
    "\n",
    "article_id= articles['article_id'].values.tolist()\n",
    "print(article_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "377dd367",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mexpect_column_mean_to_be_between(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle_color_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m500\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(transactions_faulty_df\u001b[38;5;241m.\u001b[39mexpect_column_values_to_be_in_set(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle_id\u001b[39m\u001b[38;5;124m'\u001b[39m, article_id))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(transactions_faulty_df.expect_column_values_to_be_in_set('article_id', article_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb178f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe05297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
